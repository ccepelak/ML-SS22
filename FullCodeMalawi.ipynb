{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis using Malawi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannes/opt/anaconda3/lib/python3.8/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as sts\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "import random as rd\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import decomposition\n",
    "from sklearn import pipeline\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "\n",
    "#from skimage import io, color\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,  GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pygeos\n",
    "import ntpath\n",
    "import geopandas as gpd\n",
    "#import geoplot\n",
    "from shapely.geometry import Point, Polygon\n",
    "from fiona.crs import from_epsg\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allow your container to understand gpu errors from the system \n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_HOME'] = '/workspace/cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "#change GPU\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES= 0,1,2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and transform images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed for reproducibility\n",
    "rd.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_size = int(input(\"Please input an integer (maybe like 300)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the pathlinks to the images\n",
    "raw_images_links = glob(\"image_data/malawi_archive/images/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transform the images into arrays\n",
    "malawi_arrays = [np.array(Image.open(file_name)) for file_name in raw_images_links]\n",
    "malawi_arrays[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for identity:\n",
    "def is_arr_in_list(myarr, list_arrays):\n",
    "    return next((True for elem in list_arrays if elem is myarr), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## New try\\nmalawi_unique = []\\nunique_indices = []\\nfor id, file_name in enumerate(raw_images_links):\\n    im_array = np.array(Image.open(file_name))\\n\\n    if id == 0:\\n        malawi_unique.append(im_array)\\n        unique_indices.append(id)\\n\\n    if is_arr_in_list(im_array, malawi_unique) == False:\\n        malawi_unique.append(im_array)\\n        unique_indices.append(id)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## New try\n",
    "malawi_unique = []\n",
    "unique_indices = []\n",
    "for id, file_name in enumerate(raw_images_links):\n",
    "    im_array = np.array(Image.open(file_name))\n",
    "\n",
    "    if id == 0:\n",
    "        malawi_unique.append(im_array)\n",
    "        unique_indices.append(id)\n",
    "\n",
    "    if is_arr_in_list(im_array, malawi_unique) == False:\n",
    "        malawi_unique.append(im_array)\n",
    "        unique_indices.append(id)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the data and resize if necessary\n",
    "\n",
    "#resize the data and flatten it\n",
    "def transform(dataset):\n",
    "    new_list = []\n",
    "    for i in range(len(dataset)):\n",
    "        #resize the image\n",
    "        temp2 = resize(dataset[i], (256, 256), Image.NEAREST)\n",
    "        \n",
    "        #flatten it\n",
    "        new_list.append(temp2.flatten())\n",
    "\n",
    "    return new_list\n",
    "\n",
    "#do this for malawi\n",
    "malawi_transform = transform(malawi_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262144,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malawi_transform[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed training the PCA for filtering with 50 samples and 20 components. \n",
      "var expl: 92%\n"
     ]
    }
   ],
   "source": [
    "n_samples = 50\n",
    "n_comps_filter =20\n",
    "pca_filter = PCA(n_comps_filter)\n",
    "pca_filter.fit(rd.sample(malawi_transform, n_samples))\n",
    "print(f\"Completed training the PCA for filtering with {n_samples} samples and {n_comps_filter} components. \\nvar expl: {round(np.cumsum(pca_filter.explained_variance_ratio_)[n_comps_filter-1]*100)}%\")\n",
    "malawi_pca_filter = pca_filter.transform(malawi_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malawi_unique, unique_indices = np.unique(malawi_pca_filter, axis= 0, return_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#malawi_filtered = pca_filter.inverse_transform(malawi_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data using StandardScaler\n",
    "#StandarScaler normalies the images by subtracting the mean and dividing by the unit variance. \n",
    "def return_scaled(input_array):\n",
    "    scaler = StandardScaler(copy=False)\n",
    "    scaler.fit(rd.sample(input_array,1000))\n",
    "    data_set = scaler.fit_transform(input_array)\n",
    "\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"stages = []\n",
    "assemblerInputs = malawi_transform\n",
    "assemblerInputs = [column for column in assemblerInputs if column not in columns_to_remove_from_assembler]\n",
    "#add vector assembler\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features_nonscaled\")\n",
    "stages += [assembler]\n",
    "\n",
    "col_scaler = StandardScaler(inputCol='features_nonscaled', outputCol='features',withStd=True, withMean=False)\n",
    "stages += [col_scaler]\n",
    "\n",
    "pipeline = Pipeline(stages = stages)\n",
    "assemblerModel = pipeline.fit(df)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the image data with the outcome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the location of the images \n",
    "image_geodf = gpd.GeoDataFrame() # Create an empty geopandas GeoDataFrame\n",
    "for i in unique_indices:\n",
    "    #extract an array of the geo points from the file name \n",
    "    point_array = [float(point) for point in str.split(ntpath.basename(raw_images_links[i][:-4]),\"_\")]\n",
    "\n",
    "    lat_i = 1\n",
    "    long_i = 0\n",
    "    #calculate the width of the image taken\n",
    "    #https://wiki.openstreetmap.org/wiki/Zoom_levels \n",
    "    meters = 40075016.686 * math.cos(math.radians(point_array[lat_i]))/(2**14)\n",
    "\n",
    "    #the tiles are x-meters wide. Let's find that in degrees: \n",
    "    # (https://stackoverflow.com/questions/25237356/convert-meters-to-decimal-degrees)\n",
    "    width_deg_half = (meters / (111.32 * 1000 * math.cos(point_array[lat_i] * (math.pi / 180))))/2\n",
    "\n",
    "    geo_point = [(point_array[lat_i] - width_deg_half, point_array[long_i]+ width_deg_half),\n",
    "                (point_array[lat_i] + width_deg_half, point_array[long_i]+ width_deg_half),\n",
    "                (point_array[lat_i] + width_deg_half, point_array[long_i] - width_deg_half),\n",
    "                (point_array[lat_i] - width_deg_half, point_array[long_i] - width_deg_half)]\n",
    "\n",
    "    # Create a Shapely polygon from the coordinate-tuple list\n",
    "    image_geodf.loc[i, 'geometry'] = Polygon(geo_point)\n",
    "    # assign an image id. used for merging with actual images and the survey values\n",
    "    image_geodf.loc[i, 'image_id'] = i  \n",
    "\n",
    "    # Set the GeoDataFrame's coordinate system to WGS84 (i.e. epsg code 4326)\n",
    "image_geodf.crs = from_epsg(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load outcome data\n",
    "outcome_geodf = gpd.read_file(\"outcome_data/ml_gdf.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have a look \n",
    "outcome_geodf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge based on whether an image contains the point \n",
    "geo_df = geopandas.sjoin(image_geodf, outcome_geodf, how=\"inner\", op = \"contains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the merged geodata frame\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "ax = image_geodf.plot(facecolor='grey')\n",
    "outcome_geodf.plot(ax=ax, color='blue', markersize = .001, alpha = 0.2)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### peak into the data\n",
    "\n",
    "n_col = 5\n",
    "n_row = 4\n",
    "## show the original images\n",
    "plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n",
    "plt.suptitle('Original photos', size=16)\n",
    "\n",
    "#loop through some random images\n",
    "for i, comp in enumerate(malawi_transform[:n_col*n_row]):\n",
    "    plt.subplot(n_col, n_row, i + 1)\n",
    "    #comp = scaler.inverse_transform(comp)\n",
    "    comp = (comp * 255).astype(np.uint8)\n",
    "    plt.imshow(comp.reshape(256,256,4))\n",
    "    plt.title(i)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.04, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create plot wiht Malawi outline\n",
    "\"\"\"world = gpd.read_file(\n",
    "    gpd.datasets.get_path('naturalearth_lowres'))\n",
    "ax = geoplot.polyplot(image_geodf, color = 'grey')\n",
    "geoplot.polyplot(world.query('name == \"Malawi\"'), ax = ax)\n",
    "outcome_geodf.plot(markersize = 0.01, alpha = 0.2, ax = ax)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select a single image by it's ID to be printed\n",
    "comp = malawi_transform[1]\n",
    "#comp = scaler.inverse_transform(comp)\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "comp = (comp * 255).astype(np.uint8)\n",
    "plt.imshow(comp.reshape(256,256,4))\n",
    "\n",
    "comp = malawi_transform[1784]\n",
    "plt.subplot(1, 2, 2)\n",
    "comp = (comp * 255).astype(np.uint8)\n",
    "plt.imshow(comp.reshape(256,256,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates \n",
    "\n",
    "print(raw_images_links[1])\n",
    "print(raw_images_links[1784])\n",
    "\n",
    "\n",
    "np.mean(np.asarray(Image.open(raw_images_links[1])) == np.asarray(Image.open(raw_images_links[1784])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make empty lists\n",
    "X_full = []\n",
    "Y_full = []\n",
    "#fill them with the image data and the outcome data\n",
    "for i in range(len(geo_df)):\n",
    "    obs = geo_df.iloc[i]\n",
    "    X_full.append(malawi_transform[int(obs['image_id'])])\n",
    "    Y_full.append(obs['hv271'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, Y_full, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find how many components we should use by just applying a PCA with a range of components\n",
    "\n",
    "#initialize the pca\n",
    "pca = PCA(whiten=True, copy=True, random_state= 10)\n",
    "#fit it\n",
    "pca.fit(rd.sample(X_train,100))\n",
    "\n",
    "#get the cumulative \n",
    "total = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      2\u001b[0m comp_to_view \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#let's plot it\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "comp_to_view = 25\n",
    "#let's plot it\n",
    "plot_xs = list(range(comp_to_view))\n",
    "\n",
    "\n",
    "plt.scatter(plot_xs, pca.explained_variance_ratio_[:comp_to_view], color='black', label='Explained variance proportion')\n",
    "plt.scatter(plot_xs, total[:comp_to_view],color='orange', label='Total')\n",
    "\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel('Number of Component', size=16)\n",
    "plt.ylabel('Variance Explained (%)', size=16)\n",
    "#plt.hlines(0.,xmin=0, xmax=comp_to_view, colors = 'blue', linestyles='--')\n",
    "plt.grid('minor')\n",
    "plt.show()\n",
    "\n",
    "print(pca.explained_variance_ratio_[:comp_to_view])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=25, random_state=10, whiten=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the pca\n",
    "\n",
    "n_comp = 25\n",
    "pca = PCA(n_components = n_comp, whiten=True, copy=True, random_state= 10)\n",
    "\n",
    "#fit with random sample of _ observations\n",
    "pca.fit(rd.sample(X_train,1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 262144)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## batchwise transformation of the \n",
    "\n",
    "reduced = []\n",
    "batchsize = 2500\n",
    "# \n",
    "for i in range(0, len(X_train), batchsize):\n",
    "    if i == 0:\n",
    "        reduced = pca.transform(X_train[i:i+batchsize])\n",
    "        continue \n",
    "    \n",
    "    reduced_batch = pca.transform(X_train[i:i+batchsize])\n",
    "    reduced = np.concatenate((reduced, reduced_batch), axis =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideas from Will\n",
    "# Kernel Trick \n",
    "# Random Projection\n",
    "# IRLS (iterarated reweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = np.asarray(reduced)\n",
    "n_obs = len(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_pca, y_train).to_csv(\"train_set_pca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11150"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(X_train_pca[:,1]))\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "#function straight copied from\n",
    "def plot_gallery(title, images, n_col=n_col, n_row=n_row, cmap_p=plt.cm.gray):\n",
    "    plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n",
    "    plt.suptitle(title, size=16)\n",
    "    for i, comp in enumerate(images):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        vmax = max(comp.max(), -comp.min())\n",
    "        #print(vmax)\n",
    "        plt.imshow((comp*255).astype(np.uint8),\n",
    "                   interpolation='nearest',\n",
    "                   vmin=-vmax, vmax=vmax \n",
    "                   #cmap = cmap_p\n",
    "                   )\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "    plt.subplots_adjust(0.01, 0.05, 0.99, 0.93, 0.04, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#eigenimages[:,:,:,-1] += .5\\neigenimages[:,:,:,0] += np.mean(eigenimages[:,:,:,0])\\neigenimages[:,:,:,1] += np.mean(eigenimages[:,:,:,1])\\neigenimages[:,:,:,2] += np.mean(eigenimages[:,:,:,2])'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenimages = pca.components_.reshape(25,256,256,4).copy()\n",
    "\"\"\"#eigenimages[:,:,:,-1] += .5\n",
    "eigenimages[:,:,:,0] += np.mean(eigenimages[:,:,:,0])\n",
    "eigenimages[:,:,:,1] += np.mean(eigenimages[:,:,:,1])\n",
    "eigenimages[:,:,:,2] += np.mean(eigenimages[:,:,:,2])\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.973359796885341e-05"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(eigenimages[:,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gallery(\"PCA\", eigenimages[:,:,:,:3], n_col=5, n_row=5, cmap_p = plt.cm.viridis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear regression with full un-PCAed data blows up the kernel\n",
    "# DO NOT RUN WITH EXTRA DATA\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03143548281893427"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_model.score(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12130"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(X_train_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2883., 4362., 2136., 1303.,  999.,  761.,  640.,  437.,  282.,\n",
       "          74.]),\n",
       " array([-122719. ,  -70784.6,  -18850.2,   33084.2,   85018.6,  136953. ,\n",
       "         188887.4,  240821.8,  292756.2,  344690.6,  396625. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist((y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators= 100, bootstrap = True)\n",
    "rf.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.511687101947754"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Grid Search on Random Forest Regressor\n",
    "\n",
    "Source and documentation: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "Tuning: \n",
    "- n_estimators: number of trees in the forest\n",
    "- max_depth: maximum depth of the tree \n",
    "- max_features: number of features taken into account when splitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_n_list = [100]\n",
    "hyper_depth_list = [1,2,3,4,5, 10,16,18,20,22,24,26, 30, 40, 50, 100, 200]\n",
    "hyper_m_list = [\"auto\", \"sqrt\", \"log2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 51 candidates, totalling 204 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=RandomForestRegressor(random_state=0), n_jobs=-1,\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5, 10, 16, 18, 20, 22, 24,\n",
       "                                       26, 30, 40, 50, 100, 200],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [100]},\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=0),\n",
    "                           {\n",
    "                              'n_estimators':[100],\n",
    "                              'max_depth': hyper_depth_list,\n",
    "                              'max_features': hyper_m_list,\n",
    "                            },cv=4, scoring=\"r2\",verbose=1,n_jobs=-1\n",
    "                           )\n",
    "grid_search.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.644555</td>\n",
       "      <td>0.035414</td>\n",
       "      <td>0.007870</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.048964</td>\n",
       "      <td>0.030840</td>\n",
       "      <td>0.031855</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>0.034745</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.240566</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>1</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>0.041466</td>\n",
       "      <td>0.034192</td>\n",
       "      <td>0.036732</td>\n",
       "      <td>0.034858</td>\n",
       "      <td>0.036812</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.207364</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>1</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>0.040072</td>\n",
       "      <td>0.032951</td>\n",
       "      <td>0.035454</td>\n",
       "      <td>0.033326</td>\n",
       "      <td>0.035451</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.109759</td>\n",
       "      <td>0.021557</td>\n",
       "      <td>0.009499</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.091548</td>\n",
       "      <td>0.068843</td>\n",
       "      <td>0.071177</td>\n",
       "      <td>0.062278</td>\n",
       "      <td>0.073462</td>\n",
       "      <td>0.010940</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.349374</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>0.085829</td>\n",
       "      <td>0.070998</td>\n",
       "      <td>0.078749</td>\n",
       "      <td>0.072455</td>\n",
       "      <td>0.077007</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.302731</td>\n",
       "      <td>0.009610</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>0.084441</td>\n",
       "      <td>0.068694</td>\n",
       "      <td>0.074985</td>\n",
       "      <td>0.071022</td>\n",
       "      <td>0.074785</td>\n",
       "      <td>0.006011</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.577747</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.155516</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>0.126865</td>\n",
       "      <td>0.112003</td>\n",
       "      <td>0.128271</td>\n",
       "      <td>0.016587</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.441595</td>\n",
       "      <td>0.024711</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>0.140247</td>\n",
       "      <td>0.116695</td>\n",
       "      <td>0.127806</td>\n",
       "      <td>0.118533</td>\n",
       "      <td>0.125820</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.376466</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>3</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>0.134051</td>\n",
       "      <td>0.109755</td>\n",
       "      <td>0.122321</td>\n",
       "      <td>0.113631</td>\n",
       "      <td>0.119940</td>\n",
       "      <td>0.009332</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.057587</td>\n",
       "      <td>0.039894</td>\n",
       "      <td>0.014929</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.228230</td>\n",
       "      <td>0.177709</td>\n",
       "      <td>0.189592</td>\n",
       "      <td>0.169711</td>\n",
       "      <td>0.191311</td>\n",
       "      <td>0.022459</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.511502</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>4</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>0.196886</td>\n",
       "      <td>0.168827</td>\n",
       "      <td>0.180384</td>\n",
       "      <td>0.169914</td>\n",
       "      <td>0.179003</td>\n",
       "      <td>0.011268</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.441680</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.014880</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>4</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>0.194873</td>\n",
       "      <td>0.161279</td>\n",
       "      <td>0.173889</td>\n",
       "      <td>0.164607</td>\n",
       "      <td>0.173662</td>\n",
       "      <td>0.013089</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.532773</td>\n",
       "      <td>0.020352</td>\n",
       "      <td>0.016902</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'auto', 'n_es...</td>\n",
       "      <td>0.288916</td>\n",
       "      <td>0.237771</td>\n",
       "      <td>0.248198</td>\n",
       "      <td>0.239069</td>\n",
       "      <td>0.253489</td>\n",
       "      <td>0.020845</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.616392</td>\n",
       "      <td>0.016775</td>\n",
       "      <td>0.015212</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>5</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'n_es...</td>\n",
       "      <td>0.262070</td>\n",
       "      <td>0.221789</td>\n",
       "      <td>0.230363</td>\n",
       "      <td>0.224254</td>\n",
       "      <td>0.234619</td>\n",
       "      <td>0.016153</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.534406</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.015346</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>5</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'n_es...</td>\n",
       "      <td>0.251778</td>\n",
       "      <td>0.216313</td>\n",
       "      <td>0.223755</td>\n",
       "      <td>0.218431</td>\n",
       "      <td>0.227569</td>\n",
       "      <td>0.014238</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.350351</td>\n",
       "      <td>0.063192</td>\n",
       "      <td>0.033376</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.453489</td>\n",
       "      <td>0.420490</td>\n",
       "      <td>0.419295</td>\n",
       "      <td>0.432159</td>\n",
       "      <td>0.431358</td>\n",
       "      <td>0.013730</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.990485</td>\n",
       "      <td>0.006207</td>\n",
       "      <td>0.030471</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.436874</td>\n",
       "      <td>0.411550</td>\n",
       "      <td>0.408980</td>\n",
       "      <td>0.415840</td>\n",
       "      <td>0.418311</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.859326</td>\n",
       "      <td>0.024344</td>\n",
       "      <td>0.031071</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.440284</td>\n",
       "      <td>0.406125</td>\n",
       "      <td>0.402741</td>\n",
       "      <td>0.408673</td>\n",
       "      <td>0.414456</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.564263</td>\n",
       "      <td>0.115269</td>\n",
       "      <td>0.050271</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>16</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 16, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.480542</td>\n",
       "      <td>0.458526</td>\n",
       "      <td>0.476808</td>\n",
       "      <td>0.483374</td>\n",
       "      <td>0.474812</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.269419</td>\n",
       "      <td>0.022327</td>\n",
       "      <td>0.043235</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>16</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 16, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.480376</td>\n",
       "      <td>0.456743</td>\n",
       "      <td>0.474424</td>\n",
       "      <td>0.483267</td>\n",
       "      <td>0.473702</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.103481</td>\n",
       "      <td>0.043225</td>\n",
       "      <td>0.043426</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>16</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 16, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.479854</td>\n",
       "      <td>0.456989</td>\n",
       "      <td>0.473823</td>\n",
       "      <td>0.481925</td>\n",
       "      <td>0.473148</td>\n",
       "      <td>0.009793</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.095935</td>\n",
       "      <td>0.088539</td>\n",
       "      <td>0.046211</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>18</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 18, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.480031</td>\n",
       "      <td>0.457035</td>\n",
       "      <td>0.478689</td>\n",
       "      <td>0.483672</td>\n",
       "      <td>0.474857</td>\n",
       "      <td>0.010450</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.348199</td>\n",
       "      <td>0.042910</td>\n",
       "      <td>0.045730</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>18</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 18, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.479881</td>\n",
       "      <td>0.457203</td>\n",
       "      <td>0.477864</td>\n",
       "      <td>0.483387</td>\n",
       "      <td>0.474584</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.149067</td>\n",
       "      <td>0.028744</td>\n",
       "      <td>0.046014</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>18</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 18, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.480794</td>\n",
       "      <td>0.457341</td>\n",
       "      <td>0.477724</td>\n",
       "      <td>0.483684</td>\n",
       "      <td>0.474886</td>\n",
       "      <td>0.010346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.004471</td>\n",
       "      <td>0.129925</td>\n",
       "      <td>0.044040</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>20</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.479514</td>\n",
       "      <td>0.456264</td>\n",
       "      <td>0.478709</td>\n",
       "      <td>0.483523</td>\n",
       "      <td>0.474502</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.385995</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>0.048421</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>20</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.479569</td>\n",
       "      <td>0.456505</td>\n",
       "      <td>0.478682</td>\n",
       "      <td>0.483654</td>\n",
       "      <td>0.474602</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.220707</td>\n",
       "      <td>0.012307</td>\n",
       "      <td>0.049298</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>20</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.479497</td>\n",
       "      <td>0.456640</td>\n",
       "      <td>0.478753</td>\n",
       "      <td>0.483850</td>\n",
       "      <td>0.474685</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.178040</td>\n",
       "      <td>0.146990</td>\n",
       "      <td>0.043310</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>22</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 22, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.479206</td>\n",
       "      <td>0.456038</td>\n",
       "      <td>0.478559</td>\n",
       "      <td>0.483459</td>\n",
       "      <td>0.474315</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.541586</td>\n",
       "      <td>0.082710</td>\n",
       "      <td>0.050780</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>22</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 22, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.479255</td>\n",
       "      <td>0.456323</td>\n",
       "      <td>0.478654</td>\n",
       "      <td>0.483455</td>\n",
       "      <td>0.474422</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.237849</td>\n",
       "      <td>0.034986</td>\n",
       "      <td>0.051274</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>22</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 22, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.479429</td>\n",
       "      <td>0.456237</td>\n",
       "      <td>0.478707</td>\n",
       "      <td>0.483644</td>\n",
       "      <td>0.474504</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.053895</td>\n",
       "      <td>0.069269</td>\n",
       "      <td>0.042326</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>24</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 24, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.479129</td>\n",
       "      <td>0.455933</td>\n",
       "      <td>0.478506</td>\n",
       "      <td>0.483428</td>\n",
       "      <td>0.474249</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.500583</td>\n",
       "      <td>0.027825</td>\n",
       "      <td>0.050987</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>24</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 24, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.479136</td>\n",
       "      <td>0.456004</td>\n",
       "      <td>0.478520</td>\n",
       "      <td>0.483457</td>\n",
       "      <td>0.474279</td>\n",
       "      <td>0.010721</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.396678</td>\n",
       "      <td>0.157551</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>24</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 24, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.479196</td>\n",
       "      <td>0.456012</td>\n",
       "      <td>0.478519</td>\n",
       "      <td>0.483356</td>\n",
       "      <td>0.474271</td>\n",
       "      <td>0.010703</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6.229079</td>\n",
       "      <td>0.223725</td>\n",
       "      <td>0.041764</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>26</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 26, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.479102</td>\n",
       "      <td>0.455907</td>\n",
       "      <td>0.478480</td>\n",
       "      <td>0.483388</td>\n",
       "      <td>0.474219</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.585562</td>\n",
       "      <td>0.092606</td>\n",
       "      <td>0.050982</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>26</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 26, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.479100</td>\n",
       "      <td>0.455952</td>\n",
       "      <td>0.478505</td>\n",
       "      <td>0.483399</td>\n",
       "      <td>0.474239</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.411306</td>\n",
       "      <td>0.066022</td>\n",
       "      <td>0.051752</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>26</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 26, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.479138</td>\n",
       "      <td>0.455907</td>\n",
       "      <td>0.478497</td>\n",
       "      <td>0.483423</td>\n",
       "      <td>0.474241</td>\n",
       "      <td>0.010754</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.934224</td>\n",
       "      <td>0.104029</td>\n",
       "      <td>0.041889</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 30, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455902</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474219</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.809726</td>\n",
       "      <td>0.294612</td>\n",
       "      <td>0.055741</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>30</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 30, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478485</td>\n",
       "      <td>0.483390</td>\n",
       "      <td>0.474219</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.541171</td>\n",
       "      <td>0.150801</td>\n",
       "      <td>0.053163</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>30</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 30, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.479104</td>\n",
       "      <td>0.455906</td>\n",
       "      <td>0.478485</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474221</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.940759</td>\n",
       "      <td>0.243972</td>\n",
       "      <td>0.041493</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>40</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 40, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.613520</td>\n",
       "      <td>0.111897</td>\n",
       "      <td>0.052252</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>40</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 40, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.584618</td>\n",
       "      <td>0.113473</td>\n",
       "      <td>0.055680</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>40</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 40, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5.738464</td>\n",
       "      <td>0.037050</td>\n",
       "      <td>0.041488</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>50</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'auto', 'n_e...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.649549</td>\n",
       "      <td>0.124502</td>\n",
       "      <td>0.051971</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>50</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'n_e...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.407748</td>\n",
       "      <td>0.079089</td>\n",
       "      <td>0.052754</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>50</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'n_e...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.614753</td>\n",
       "      <td>0.077957</td>\n",
       "      <td>0.041204</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'auto', 'n_...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.622117</td>\n",
       "      <td>0.052366</td>\n",
       "      <td>0.050577</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'n_...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.457957</td>\n",
       "      <td>0.102970</td>\n",
       "      <td>0.050163</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>100</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 100, 'max_features': 'log2', 'n_...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.514044</td>\n",
       "      <td>0.155091</td>\n",
       "      <td>0.040435</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>200</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 200, 'max_features': 'auto', 'n_...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.621806</td>\n",
       "      <td>0.118024</td>\n",
       "      <td>0.046489</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>200</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 200, 'max_features': 'sqrt', 'n_...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.287609</td>\n",
       "      <td>0.055139</td>\n",
       "      <td>0.047609</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 200, 'max_features': 'log2', 'n_...</td>\n",
       "      <td>0.479099</td>\n",
       "      <td>0.455901</td>\n",
       "      <td>0.478482</td>\n",
       "      <td>0.483391</td>\n",
       "      <td>0.474218</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.644555      0.035414         0.007870        0.000142   \n",
       "1        0.240566      0.013707         0.008156        0.000208   \n",
       "2        0.207364      0.001025         0.008246        0.000147   \n",
       "3        1.109759      0.021557         0.009499        0.000315   \n",
       "4        0.349374      0.010830         0.009933        0.000266   \n",
       "5        0.302731      0.009610         0.009726        0.000200   \n",
       "6        1.577747      0.007671         0.011729        0.000400   \n",
       "7        0.441595      0.024711         0.011324        0.000235   \n",
       "8        0.376466      0.018628         0.011410        0.000223   \n",
       "9        2.057587      0.039894         0.014929        0.000140   \n",
       "10       0.511502      0.001634         0.013191        0.000280   \n",
       "11       0.441680      0.002962         0.014880        0.002790   \n",
       "12       2.532773      0.020352         0.016902        0.000372   \n",
       "13       0.616392      0.016775         0.015212        0.000272   \n",
       "14       0.534406      0.015252         0.015346        0.000525   \n",
       "15       4.350351      0.063192         0.033376        0.000307   \n",
       "16       0.990485      0.006207         0.030471        0.000854   \n",
       "17       0.859326      0.024344         0.031071        0.001068   \n",
       "18       5.564263      0.115269         0.050271        0.005398   \n",
       "19       1.269419      0.022327         0.043235        0.000467   \n",
       "20       1.103481      0.043225         0.043426        0.001514   \n",
       "21       6.095935      0.088539         0.046211        0.000287   \n",
       "22       1.348199      0.042910         0.045730        0.000630   \n",
       "23       1.149067      0.028744         0.046014        0.000579   \n",
       "24       6.004471      0.129925         0.044040        0.000777   \n",
       "25       1.385995      0.027813         0.048421        0.000215   \n",
       "26       1.220707      0.012307         0.049298        0.000444   \n",
       "27       6.178040      0.146990         0.043310        0.001071   \n",
       "28       1.541586      0.082710         0.050780        0.000462   \n",
       "29       1.237849      0.034986         0.051274        0.000674   \n",
       "30       6.053895      0.069269         0.042326        0.000387   \n",
       "31       1.500583      0.027825         0.050987        0.000339   \n",
       "32       1.396678      0.157551         0.052300        0.003094   \n",
       "33       6.229079      0.223725         0.041764        0.000118   \n",
       "34       1.585562      0.092606         0.050982        0.001397   \n",
       "35       1.411306      0.066022         0.051752        0.001508   \n",
       "36       5.934224      0.104029         0.041889        0.000638   \n",
       "37       1.809726      0.294612         0.055741        0.005457   \n",
       "38       1.541171      0.150801         0.053163        0.003718   \n",
       "39       5.940759      0.243972         0.041493        0.000215   \n",
       "40       1.613520      0.111897         0.052252        0.000389   \n",
       "41       1.584618      0.113473         0.055680        0.003457   \n",
       "42       5.738464      0.037050         0.041488        0.000497   \n",
       "43       1.649549      0.124502         0.051971        0.000992   \n",
       "44       1.407748      0.079089         0.052754        0.002982   \n",
       "45       5.614753      0.077957         0.041204        0.000399   \n",
       "46       1.622117      0.052366         0.050577        0.000451   \n",
       "47       1.457957      0.102970         0.050163        0.001100   \n",
       "48       5.514044      0.155091         0.040435        0.000535   \n",
       "49       1.621806      0.118024         0.046489        0.000723   \n",
       "50       1.287609      0.055139         0.047609        0.000388   \n",
       "\n",
       "   param_max_depth param_max_features param_n_estimators  \\\n",
       "0                1               auto                100   \n",
       "1                1               sqrt                100   \n",
       "2                1               log2                100   \n",
       "3                2               auto                100   \n",
       "4                2               sqrt                100   \n",
       "5                2               log2                100   \n",
       "6                3               auto                100   \n",
       "7                3               sqrt                100   \n",
       "8                3               log2                100   \n",
       "9                4               auto                100   \n",
       "10               4               sqrt                100   \n",
       "11               4               log2                100   \n",
       "12               5               auto                100   \n",
       "13               5               sqrt                100   \n",
       "14               5               log2                100   \n",
       "15              10               auto                100   \n",
       "16              10               sqrt                100   \n",
       "17              10               log2                100   \n",
       "18              16               auto                100   \n",
       "19              16               sqrt                100   \n",
       "20              16               log2                100   \n",
       "21              18               auto                100   \n",
       "22              18               sqrt                100   \n",
       "23              18               log2                100   \n",
       "24              20               auto                100   \n",
       "25              20               sqrt                100   \n",
       "26              20               log2                100   \n",
       "27              22               auto                100   \n",
       "28              22               sqrt                100   \n",
       "29              22               log2                100   \n",
       "30              24               auto                100   \n",
       "31              24               sqrt                100   \n",
       "32              24               log2                100   \n",
       "33              26               auto                100   \n",
       "34              26               sqrt                100   \n",
       "35              26               log2                100   \n",
       "36              30               auto                100   \n",
       "37              30               sqrt                100   \n",
       "38              30               log2                100   \n",
       "39              40               auto                100   \n",
       "40              40               sqrt                100   \n",
       "41              40               log2                100   \n",
       "42              50               auto                100   \n",
       "43              50               sqrt                100   \n",
       "44              50               log2                100   \n",
       "45             100               auto                100   \n",
       "46             100               sqrt                100   \n",
       "47             100               log2                100   \n",
       "48             200               auto                100   \n",
       "49             200               sqrt                100   \n",
       "50             200               log2                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_depth': 1, 'max_features': 'auto', 'n_es...           0.048964   \n",
       "1   {'max_depth': 1, 'max_features': 'sqrt', 'n_es...           0.041466   \n",
       "2   {'max_depth': 1, 'max_features': 'log2', 'n_es...           0.040072   \n",
       "3   {'max_depth': 2, 'max_features': 'auto', 'n_es...           0.091548   \n",
       "4   {'max_depth': 2, 'max_features': 'sqrt', 'n_es...           0.085829   \n",
       "5   {'max_depth': 2, 'max_features': 'log2', 'n_es...           0.084441   \n",
       "6   {'max_depth': 3, 'max_features': 'auto', 'n_es...           0.155516   \n",
       "7   {'max_depth': 3, 'max_features': 'sqrt', 'n_es...           0.140247   \n",
       "8   {'max_depth': 3, 'max_features': 'log2', 'n_es...           0.134051   \n",
       "9   {'max_depth': 4, 'max_features': 'auto', 'n_es...           0.228230   \n",
       "10  {'max_depth': 4, 'max_features': 'sqrt', 'n_es...           0.196886   \n",
       "11  {'max_depth': 4, 'max_features': 'log2', 'n_es...           0.194873   \n",
       "12  {'max_depth': 5, 'max_features': 'auto', 'n_es...           0.288916   \n",
       "13  {'max_depth': 5, 'max_features': 'sqrt', 'n_es...           0.262070   \n",
       "14  {'max_depth': 5, 'max_features': 'log2', 'n_es...           0.251778   \n",
       "15  {'max_depth': 10, 'max_features': 'auto', 'n_e...           0.453489   \n",
       "16  {'max_depth': 10, 'max_features': 'sqrt', 'n_e...           0.436874   \n",
       "17  {'max_depth': 10, 'max_features': 'log2', 'n_e...           0.440284   \n",
       "18  {'max_depth': 16, 'max_features': 'auto', 'n_e...           0.480542   \n",
       "19  {'max_depth': 16, 'max_features': 'sqrt', 'n_e...           0.480376   \n",
       "20  {'max_depth': 16, 'max_features': 'log2', 'n_e...           0.479854   \n",
       "21  {'max_depth': 18, 'max_features': 'auto', 'n_e...           0.480031   \n",
       "22  {'max_depth': 18, 'max_features': 'sqrt', 'n_e...           0.479881   \n",
       "23  {'max_depth': 18, 'max_features': 'log2', 'n_e...           0.480794   \n",
       "24  {'max_depth': 20, 'max_features': 'auto', 'n_e...           0.479514   \n",
       "25  {'max_depth': 20, 'max_features': 'sqrt', 'n_e...           0.479569   \n",
       "26  {'max_depth': 20, 'max_features': 'log2', 'n_e...           0.479497   \n",
       "27  {'max_depth': 22, 'max_features': 'auto', 'n_e...           0.479206   \n",
       "28  {'max_depth': 22, 'max_features': 'sqrt', 'n_e...           0.479255   \n",
       "29  {'max_depth': 22, 'max_features': 'log2', 'n_e...           0.479429   \n",
       "30  {'max_depth': 24, 'max_features': 'auto', 'n_e...           0.479129   \n",
       "31  {'max_depth': 24, 'max_features': 'sqrt', 'n_e...           0.479136   \n",
       "32  {'max_depth': 24, 'max_features': 'log2', 'n_e...           0.479196   \n",
       "33  {'max_depth': 26, 'max_features': 'auto', 'n_e...           0.479102   \n",
       "34  {'max_depth': 26, 'max_features': 'sqrt', 'n_e...           0.479100   \n",
       "35  {'max_depth': 26, 'max_features': 'log2', 'n_e...           0.479138   \n",
       "36  {'max_depth': 30, 'max_features': 'auto', 'n_e...           0.479099   \n",
       "37  {'max_depth': 30, 'max_features': 'sqrt', 'n_e...           0.479099   \n",
       "38  {'max_depth': 30, 'max_features': 'log2', 'n_e...           0.479104   \n",
       "39  {'max_depth': 40, 'max_features': 'auto', 'n_e...           0.479099   \n",
       "40  {'max_depth': 40, 'max_features': 'sqrt', 'n_e...           0.479099   \n",
       "41  {'max_depth': 40, 'max_features': 'log2', 'n_e...           0.479099   \n",
       "42  {'max_depth': 50, 'max_features': 'auto', 'n_e...           0.479099   \n",
       "43  {'max_depth': 50, 'max_features': 'sqrt', 'n_e...           0.479099   \n",
       "44  {'max_depth': 50, 'max_features': 'log2', 'n_e...           0.479099   \n",
       "45  {'max_depth': 100, 'max_features': 'auto', 'n_...           0.479099   \n",
       "46  {'max_depth': 100, 'max_features': 'sqrt', 'n_...           0.479099   \n",
       "47  {'max_depth': 100, 'max_features': 'log2', 'n_...           0.479099   \n",
       "48  {'max_depth': 200, 'max_features': 'auto', 'n_...           0.479099   \n",
       "49  {'max_depth': 200, 'max_features': 'sqrt', 'n_...           0.479099   \n",
       "50  {'max_depth': 200, 'max_features': 'log2', 'n_...           0.479099   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0            0.030840           0.031855           0.027322         0.034745   \n",
       "1            0.034192           0.036732           0.034858         0.036812   \n",
       "2            0.032951           0.035454           0.033326         0.035451   \n",
       "3            0.068843           0.071177           0.062278         0.073462   \n",
       "4            0.070998           0.078749           0.072455         0.077007   \n",
       "5            0.068694           0.074985           0.071022         0.074785   \n",
       "6            0.118700           0.126865           0.112003         0.128271   \n",
       "7            0.116695           0.127806           0.118533         0.125820   \n",
       "8            0.109755           0.122321           0.113631         0.119940   \n",
       "9            0.177709           0.189592           0.169711         0.191311   \n",
       "10           0.168827           0.180384           0.169914         0.179003   \n",
       "11           0.161279           0.173889           0.164607         0.173662   \n",
       "12           0.237771           0.248198           0.239069         0.253489   \n",
       "13           0.221789           0.230363           0.224254         0.234619   \n",
       "14           0.216313           0.223755           0.218431         0.227569   \n",
       "15           0.420490           0.419295           0.432159         0.431358   \n",
       "16           0.411550           0.408980           0.415840         0.418311   \n",
       "17           0.406125           0.402741           0.408673         0.414456   \n",
       "18           0.458526           0.476808           0.483374         0.474812   \n",
       "19           0.456743           0.474424           0.483267         0.473702   \n",
       "20           0.456989           0.473823           0.481925         0.473148   \n",
       "21           0.457035           0.478689           0.483672         0.474857   \n",
       "22           0.457203           0.477864           0.483387         0.474584   \n",
       "23           0.457341           0.477724           0.483684         0.474886   \n",
       "24           0.456264           0.478709           0.483523         0.474502   \n",
       "25           0.456505           0.478682           0.483654         0.474602   \n",
       "26           0.456640           0.478753           0.483850         0.474685   \n",
       "27           0.456038           0.478559           0.483459         0.474315   \n",
       "28           0.456323           0.478654           0.483455         0.474422   \n",
       "29           0.456237           0.478707           0.483644         0.474504   \n",
       "30           0.455933           0.478506           0.483428         0.474249   \n",
       "31           0.456004           0.478520           0.483457         0.474279   \n",
       "32           0.456012           0.478519           0.483356         0.474271   \n",
       "33           0.455907           0.478480           0.483388         0.474219   \n",
       "34           0.455952           0.478505           0.483399         0.474239   \n",
       "35           0.455907           0.478497           0.483423         0.474241   \n",
       "36           0.455902           0.478482           0.483391         0.474219   \n",
       "37           0.455901           0.478485           0.483390         0.474219   \n",
       "38           0.455906           0.478485           0.483391         0.474221   \n",
       "39           0.455901           0.478482           0.483391         0.474218   \n",
       "40           0.455901           0.478482           0.483391         0.474218   \n",
       "41           0.455901           0.478482           0.483391         0.474218   \n",
       "42           0.455901           0.478482           0.483391         0.474218   \n",
       "43           0.455901           0.478482           0.483391         0.474218   \n",
       "44           0.455901           0.478482           0.483391         0.474218   \n",
       "45           0.455901           0.478482           0.483391         0.474218   \n",
       "46           0.455901           0.478482           0.483391         0.474218   \n",
       "47           0.455901           0.478482           0.483391         0.474218   \n",
       "48           0.455901           0.478482           0.483391         0.474218   \n",
       "49           0.455901           0.478482           0.483391         0.474218   \n",
       "50           0.455901           0.478482           0.483391         0.474218   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.008380               51  \n",
       "1         0.002844               49  \n",
       "2         0.002834               50  \n",
       "3         0.010940               48  \n",
       "4         0.005867               46  \n",
       "5         0.006011               47  \n",
       "6         0.016587               43  \n",
       "7         0.009334               44  \n",
       "8         0.009332               45  \n",
       "9         0.022459               40  \n",
       "10        0.011268               41  \n",
       "11        0.013089               42  \n",
       "12        0.020845               37  \n",
       "13        0.016153               38  \n",
       "14        0.014238               39  \n",
       "15        0.013730               34  \n",
       "16        0.010994               35  \n",
       "17        0.015060               36  \n",
       "18        0.009687                3  \n",
       "19        0.010298               32  \n",
       "20        0.009793               33  \n",
       "21        0.010450                2  \n",
       "22        0.010228                6  \n",
       "23        0.010346                1  \n",
       "24        0.010687                8  \n",
       "25        0.010616                5  \n",
       "26        0.010599                4  \n",
       "27        0.010719               10  \n",
       "28        0.010612                9  \n",
       "29        0.010714                7  \n",
       "30        0.010743               13  \n",
       "31        0.010721               11  \n",
       "32        0.010703               12  \n",
       "33        0.010740               18  \n",
       "34        0.010726               15  \n",
       "35        0.010754               14  \n",
       "36        0.010743               19  \n",
       "37        0.010743               17  \n",
       "38        0.010742               16  \n",
       "39        0.010743               20  \n",
       "40        0.010743               20  \n",
       "41        0.010743               20  \n",
       "42        0.010743               20  \n",
       "43        0.010743               20  \n",
       "44        0.010743               20  \n",
       "45        0.010743               20  \n",
       "46        0.010743               20  \n",
       "47        0.010743               20  \n",
       "48        0.010743               20  \n",
       "49        0.010743               20  \n",
       "50        0.010743               20  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_max_feature in hyper_m_list:\n",
    "    plt.plot('param_max_depth','mean_test_score',label = param_max_feature, data = cv_df[cv_df[\"param_max_features\"]== param_max_feature])\n",
    "    plt.xlabel(\"Maximum Tree Depth\")\n",
    "    plt.ylabel(\"Mean R^2\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_plot2d(df, param, outcome, group_var = None):\n",
    "\n",
    "    '''\n",
    "    func: function to plot the performance of a parameter\n",
    "    - df (dataframe): cross-validation grid search dataframe\n",
    "\n",
    "    params have to be column names in DF\n",
    "    - param (str): which parameter to asses\n",
    "    - outcome (str): which outcome to find the max for\n",
    "    - group_var (str): grouping variable (default None)\n",
    "    '''\n",
    "\n",
    "    group_var_list = np.unique(np.array(df[group_var]))\n",
    "    plt.figure(figsize=(12,8))\n",
    "    #print(np.argmax(np.asarray(df[outcome])))\n",
    "    best_score = np.max(np.asarray(df[outcome]))\n",
    "    best_score_param = np.asarray(df[param])[np.argmax(np.asarray(df[outcome]))]\n",
    "    if group_var != None:\n",
    "        best_score_group = np.asarray(df[group_var])[np.argmax(np.asarray(df[outcome]))]\n",
    "        #print(best_score_group)\n",
    "\n",
    "    if group_var == None:\n",
    "        plt.plot(param,outcome,data = df)\n",
    "        plt.xlabel(param)\n",
    "        plt.ylabel(outcome)\n",
    "        #plt.grid()\n",
    "        plt.vlines(best_score_param, 0, np.max(np.asarray(df[outcome])+.05))\n",
    "        plt.text(best_score_param,best_score + .05,  f'Best parameter: {best_score_param} with score: {best_score}',size =12)\n",
    "        plt.legend()\n",
    "    else:\n",
    "        for inst in group_var_list:\n",
    "            plt.plot(param,outcome,label = inst, data = df[df[group_var]== inst])\n",
    "            plt.xlabel(param)\n",
    "            plt.ylabel(outcome)\n",
    "            #plt.grid()\n",
    "            plt.text(best_score_param,best_score - .25,  f'Best parameter: {best_score_param} \\n with score: {round(best_score,3)} \\nin group:{best_score_group}', size = 12)\n",
    "            plt.vlines(best_score_param, 0, best_score+.05)\n",
    "            plt.legend(loc = 4)\n",
    "            plt.ylim(bottom =0 )\n",
    "    plt.grid()\n",
    "    return plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam_plot2d(cv_df, 'param_max_depth', 'mean_test_score', 'param_max_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam_plot2d(cv_df, 'param_max_features' ,'mean_test_score','param_max_depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_forest = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to apply the same pre-processing by PCA to the test set.\n",
    "X_test_pca = pca.transform(X_test)\n",
    "pd.DataFrame(X_test_pca, y_test).to_csv(\"train_set_pca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02083859676394717"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Linear Regression\n",
    "lin_model.score(X_test_pca, y_test)\n",
    "\n",
    "## My interpretation: This model is completely useless because does not attribtue for the non-linearity of the data. \n",
    "# The test R^2 being better than train means essentially nothing because the models are so bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48826702479327866"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Best forest: \n",
    "best_forest.score(X_test_pca, y_test)\n",
    "\n",
    "# This is quite good, given that the best train score of 0.504132 with an SD of like 0.06 so we are not significantly different to that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': 18,\n",
       " 'max_features': 'log2',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN \n",
    "\n",
    "* INPUT\n",
    "    * reshape back to image format\n",
    "    * resize? \n",
    "    * greyscale\n",
    "* MODEL\n",
    "    * Input\n",
    "    * Convolutional\n",
    "    * \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orienting myself on these neat tutorials:\n",
    "* https://www.datacamp.com/community/tutorials/convolutional-neural-networks-python\n",
    "* https://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras-rectified-adam in /.local/lib/python3.8/site-packages (0.20.0)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.8/dist-packages (from keras-rectified-adam) (2.8.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-rectified-adam) (1.22.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-rectified-adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import gc\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the dataset to images again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = np.asarray(X_train).reshape(n_obs, 256, 256, 4)\n",
    "#X_train_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = X_train_cnn[:,:,:,:3].astype('float32') # Taking out the fourth channel as ghe information is the same everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cnn = np.asarray(y_train).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1_cnn, X_val_cnn, y_train1_cnn, y_val_cnn = train_test_split(X_train_cnn, y_train_cnn, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jmlb.github.io/ml/2017/03/20/CoeffDetermination_CustomMetric4Keras/\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1678"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_satellite = Sequential()\n",
    "cnn_satellite.add(Conv2D(32, kernel_size=(16, 16),activation='linear',input_shape=(256,256,3),padding='same'))\n",
    "cnn_satellite.add(LeakyReLU(alpha=0.1))\n",
    "cnn_satellite.add(MaxPooling2D((2, 2),padding='same'))\n",
    "cnn_satellite.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "cnn_satellite.add(LeakyReLU(alpha=0.1))\n",
    "cnn_satellite.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_satellite.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "cnn_satellite.add(LeakyReLU(alpha=0.1))                  \n",
    "cnn_satellite.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "cnn_satellite.add(Flatten())\n",
    "cnn_satellite.add(Dense(32, activation='linear'))\n",
    "cnn_satellite.add(LeakyReLU(alpha=0.1))                  \n",
    "cnn_satellite.add(Dense(1, activation='linear'))\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_satellite.compile(loss=keras.losses.mean_squared_error, \n",
    "                      optimizer=keras.optimizers.Adam(),\n",
    "                      metrics=[coeff_determination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 256, 256, 32)      24608     \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 256, 256, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 128, 128, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 128, 128, 64)      18496     \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 64, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 32, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                4194336   \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,311,329\n",
      "Trainable params: 4,311,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_satellite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "\n",
    "epochs = 500\n",
    "batchsize = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "125/125 [==============================] - 76s 578ms/step - loss: 5902403584.0000 - coeff_determination: 0.4911 - val_loss: 6934495232.0000 - val_coeff_determination: 0.3225\n",
      "Epoch 2/500\n",
      "125/125 [==============================] - 69s 549ms/step - loss: 5922669568.0000 - coeff_determination: 0.4896 - val_loss: 6523551744.0000 - val_coeff_determination: 0.3727\n",
      "Epoch 3/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5872253952.0000 - coeff_determination: 0.4949 - val_loss: 6433839616.0000 - val_coeff_determination: 0.3812\n",
      "Epoch 4/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5899567616.0000 - coeff_determination: 0.4906 - val_loss: 6620198400.0000 - val_coeff_determination: 0.3582\n",
      "Epoch 5/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5926425600.0000 - coeff_determination: 0.4864 - val_loss: 6439604224.0000 - val_coeff_determination: 0.3841\n",
      "Epoch 6/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5884298752.0000 - coeff_determination: 0.4909 - val_loss: 6473149952.0000 - val_coeff_determination: 0.3876\n",
      "Epoch 7/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5864290304.0000 - coeff_determination: 0.4912 - val_loss: 7209344512.0000 - val_coeff_determination: 0.2946\n",
      "Epoch 8/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5927724032.0000 - coeff_determination: 0.4916 - val_loss: 6433852928.0000 - val_coeff_determination: 0.3864\n",
      "Epoch 9/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5878318080.0000 - coeff_determination: 0.4927 - val_loss: 6773656064.0000 - val_coeff_determination: 0.3416\n",
      "Epoch 10/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5850301440.0000 - coeff_determination: 0.4962 - val_loss: 6833690112.0000 - val_coeff_determination: 0.3358\n",
      "Epoch 11/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5873080320.0000 - coeff_determination: 0.4947 - val_loss: 6581897728.0000 - val_coeff_determination: 0.3620\n",
      "Epoch 12/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5839229440.0000 - coeff_determination: 0.4962 - val_loss: 6523316736.0000 - val_coeff_determination: 0.3720\n",
      "Epoch 14/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5895757824.0000 - coeff_determination: 0.4903 - val_loss: 6619885568.0000 - val_coeff_determination: 0.3599\n",
      "Epoch 15/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5836669952.0000 - coeff_determination: 0.4968 - val_loss: 6418351104.0000 - val_coeff_determination: 0.3845\n",
      "Epoch 16/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5845088768.0000 - coeff_determination: 0.4987 - val_loss: 6627257856.0000 - val_coeff_determination: 0.3574\n",
      "Epoch 17/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5863567872.0000 - coeff_determination: 0.4934 - val_loss: 7091110912.0000 - val_coeff_determination: 0.3051\n",
      "Epoch 18/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5872205824.0000 - coeff_determination: 0.4886 - val_loss: 6463951360.0000 - val_coeff_determination: 0.3822\n",
      "Epoch 19/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5843993600.0000 - coeff_determination: 0.4925 - val_loss: 6700941312.0000 - val_coeff_determination: 0.3686\n",
      "Epoch 20/500\n",
      "125/125 [==============================] - 69s 556ms/step - loss: 5844631040.0000 - coeff_determination: 0.4979 - val_loss: 6669552128.0000 - val_coeff_determination: 0.3519\n",
      "Epoch 21/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5878139904.0000 - coeff_determination: 0.4914 - val_loss: 7023540224.0000 - val_coeff_determination: 0.3141\n",
      "Epoch 22/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5843764224.0000 - coeff_determination: 0.4954 - val_loss: 6495560192.0000 - val_coeff_determination: 0.3749\n",
      "Epoch 23/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5851574272.0000 - coeff_determination: 0.4968 - val_loss: 6507732480.0000 - val_coeff_determination: 0.3789\n",
      "Epoch 24/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5834680832.0000 - coeff_determination: 0.4960 - val_loss: 6512566784.0000 - val_coeff_determination: 0.3714\n",
      "Epoch 25/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5850639360.0000 - coeff_determination: 0.4928 - val_loss: 6616303104.0000 - val_coeff_determination: 0.3592\n",
      "Epoch 26/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5856684544.0000 - coeff_determination: 0.4955 - val_loss: 6517859328.0000 - val_coeff_determination: 0.3762\n",
      "Epoch 27/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5860249088.0000 - coeff_determination: 0.4939 - val_loss: 6451809792.0000 - val_coeff_determination: 0.3810\n",
      "Epoch 28/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5811886080.0000 - coeff_determination: 0.4977 - val_loss: 6528864256.0000 - val_coeff_determination: 0.3687\n",
      "Epoch 29/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5815438848.0000 - coeff_determination: 0.5010 - val_loss: 6578136576.0000 - val_coeff_determination: 0.3628\n",
      "Epoch 30/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5837961216.0000 - coeff_determination: 0.4928 - val_loss: 6576457728.0000 - val_coeff_determination: 0.3633\n",
      "Epoch 31/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5830652928.0000 - coeff_determination: 0.4952 - val_loss: 6436024832.0000 - val_coeff_determination: 0.3818\n",
      "Epoch 32/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5820510208.0000 - coeff_determination: 0.4961 - val_loss: 6453638656.0000 - val_coeff_determination: 0.3788\n",
      "Epoch 33/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5820381696.0000 - coeff_determination: 0.4976 - val_loss: 6386466304.0000 - val_coeff_determination: 0.3891\n",
      "Epoch 34/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5832406528.0000 - coeff_determination: 0.4984 - val_loss: 6452739584.0000 - val_coeff_determination: 0.3779\n",
      "Epoch 35/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5813592064.0000 - coeff_determination: 0.4967 - val_loss: 6823722496.0000 - val_coeff_determination: 0.3340\n",
      "Epoch 36/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5831564800.0000 - coeff_determination: 0.4939 - val_loss: 6417914368.0000 - val_coeff_determination: 0.3836\n",
      "Epoch 37/500\n",
      " 53/125 [===========>..................] - ETA: 39s - loss: 5735873536.0000 - coeff_determination: 0.4946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 69s 553ms/step - loss: 5792403968.0000 - coeff_determination: 0.4995 - val_loss: 6472448000.0000 - val_coeff_determination: 0.3758\n",
      "Epoch 131/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5800313856.0000 - coeff_determination: 0.4991 - val_loss: 6490508800.0000 - val_coeff_determination: 0.3773\n",
      "Epoch 132/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5793108480.0000 - coeff_determination: 0.4994 - val_loss: 6479042560.0000 - val_coeff_determination: 0.3760\n",
      "Epoch 133/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5806678016.0000 - coeff_determination: 0.4995 - val_loss: 6569068544.0000 - val_coeff_determination: 0.3676\n",
      "Epoch 134/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5788085760.0000 - coeff_determination: 0.5000 - val_loss: 6592923648.0000 - val_coeff_determination: 0.3607\n",
      "Epoch 135/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5780228608.0000 - coeff_determination: 0.5000 - val_loss: 6517161472.0000 - val_coeff_determination: 0.3720\n",
      "Epoch 136/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5776893440.0000 - coeff_determination: 0.5003 - val_loss: 6565456896.0000 - val_coeff_determination: 0.3663\n",
      "Epoch 137/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5770563584.0000 - coeff_determination: 0.5024 - val_loss: 6537867776.0000 - val_coeff_determination: 0.3709\n",
      "Epoch 138/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5793039872.0000 - coeff_determination: 0.4988 - val_loss: 6502712320.0000 - val_coeff_determination: 0.3722\n",
      "Epoch 139/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5790909440.0000 - coeff_determination: 0.4998 - val_loss: 6510326784.0000 - val_coeff_determination: 0.3712\n",
      "Epoch 140/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5782324736.0000 - coeff_determination: 0.5000 - val_loss: 6485465088.0000 - val_coeff_determination: 0.3759\n",
      "Epoch 141/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5778369024.0000 - coeff_determination: 0.5005 - val_loss: 6420004864.0000 - val_coeff_determination: 0.3817\n",
      "Epoch 142/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5783587328.0000 - coeff_determination: 0.4986 - val_loss: 6500702720.0000 - val_coeff_determination: 0.3718\n",
      "Epoch 143/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5788822016.0000 - coeff_determination: 0.4989 - val_loss: 6749478400.0000 - val_coeff_determination: 0.3442\n",
      "Epoch 144/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5776396288.0000 - coeff_determination: 0.4995 - val_loss: 6691984896.0000 - val_coeff_determination: 0.3487\n",
      "Epoch 145/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5788816384.0000 - coeff_determination: 0.5020 - val_loss: 6509408768.0000 - val_coeff_determination: 0.3713\n",
      "Epoch 146/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5776600576.0000 - coeff_determination: 0.4989 - val_loss: 6493681664.0000 - val_coeff_determination: 0.3769\n",
      "Epoch 147/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5766456320.0000 - coeff_determination: 0.5026 - val_loss: 6476329984.0000 - val_coeff_determination: 0.3767\n",
      "Epoch 148/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5789937152.0000 - coeff_determination: 0.4981 - val_loss: 6874597376.0000 - val_coeff_determination: 0.3306\n",
      "Epoch 149/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5783655936.0000 - coeff_determination: 0.4981 - val_loss: 6495446528.0000 - val_coeff_determination: 0.3736\n",
      "Epoch 150/500\n",
      "125/125 [==============================] - 69s 552ms/step - loss: 5809036800.0000 - coeff_determination: 0.4991 - val_loss: 6480411136.0000 - val_coeff_determination: 0.3748\n",
      "Epoch 151/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5787265536.0000 - coeff_determination: 0.5006 - val_loss: 6568452096.0000 - val_coeff_determination: 0.3657\n",
      "Epoch 152/500\n",
      "125/125 [==============================] - 69s 552ms/step - loss: 5773308928.0000 - coeff_determination: 0.4994 - val_loss: 6512317952.0000 - val_coeff_determination: 0.3728\n",
      "Epoch 153/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5779228160.0000 - coeff_determination: 0.5009 - val_loss: 6623182848.0000 - val_coeff_determination: 0.3588\n",
      "Epoch 154/500\n",
      " 57/125 [============>.................] - ETA: 37s - loss: 5814675456.0000 - coeff_determination: 0.5046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 69s 554ms/step - loss: 5766774784.0000 - coeff_determination: 0.5030 - val_loss: 6622508544.0000 - val_coeff_determination: 0.3594\n",
      "Epoch 251/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5753712128.0000 - coeff_determination: 0.5034 - val_loss: 6595913216.0000 - val_coeff_determination: 0.3640\n",
      "Epoch 252/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5781568512.0000 - coeff_determination: 0.5048 - val_loss: 6534338048.0000 - val_coeff_determination: 0.3677\n",
      "Epoch 253/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5762868736.0000 - coeff_determination: 0.5023 - val_loss: 6448770560.0000 - val_coeff_determination: 0.3796\n",
      "Epoch 254/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5779975168.0000 - coeff_determination: 0.5000 - val_loss: 6492449280.0000 - val_coeff_determination: 0.3735\n",
      "Epoch 255/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5755463168.0000 - coeff_determination: 0.5036 - val_loss: 6473944576.0000 - val_coeff_determination: 0.3760\n",
      "Epoch 256/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5775008256.0000 - coeff_determination: 0.5022 - val_loss: 6492561408.0000 - val_coeff_determination: 0.3728\n",
      "Epoch 257/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5772133376.0000 - coeff_determination: 0.4984 - val_loss: 6401953792.0000 - val_coeff_determination: 0.3866\n",
      "Epoch 258/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5757058048.0000 - coeff_determination: 0.5024 - val_loss: 6467508224.0000 - val_coeff_determination: 0.3761\n",
      "Epoch 259/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5750824960.0000 - coeff_determination: 0.5048 - val_loss: 6509990400.0000 - val_coeff_determination: 0.3735\n",
      "Epoch 260/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5758406144.0000 - coeff_determination: 0.5044 - val_loss: 6863136768.0000 - val_coeff_determination: 0.3312\n",
      "Epoch 261/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5770876928.0000 - coeff_determination: 0.5013 - val_loss: 6424031232.0000 - val_coeff_determination: 0.3818\n",
      "Epoch 262/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5765964800.0000 - coeff_determination: 0.5030 - val_loss: 6410575872.0000 - val_coeff_determination: 0.3853\n",
      "Epoch 263/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5777538560.0000 - coeff_determination: 0.5006 - val_loss: 6432819712.0000 - val_coeff_determination: 0.3811\n",
      "Epoch 264/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5758821376.0000 - coeff_determination: 0.5050 - val_loss: 6516579328.0000 - val_coeff_determination: 0.3707\n",
      "Epoch 265/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5755866624.0000 - coeff_determination: 0.5016 - val_loss: 6463587328.0000 - val_coeff_determination: 0.3777\n",
      "Epoch 266/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5759743488.0000 - coeff_determination: 0.5023 - val_loss: 6493294080.0000 - val_coeff_determination: 0.3736\n",
      "Epoch 267/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5753169408.0000 - coeff_determination: 0.5027 - val_loss: 6462373888.0000 - val_coeff_determination: 0.3778\n",
      "Epoch 268/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5756993024.0000 - coeff_determination: 0.5008 - val_loss: 6512599552.0000 - val_coeff_determination: 0.3712\n",
      "Epoch 269/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5775466496.0000 - coeff_determination: 0.5029 - val_loss: 6412570112.0000 - val_coeff_determination: 0.3843\n",
      "Epoch 270/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5772559872.0000 - coeff_determination: 0.5019 - val_loss: 6680026624.0000 - val_coeff_determination: 0.3518\n",
      "Epoch 271/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5783364096.0000 - coeff_determination: 0.4988 - val_loss: 6419274752.0000 - val_coeff_determination: 0.3843\n",
      "Epoch 272/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5761248768.0000 - coeff_determination: 0.5051 - val_loss: 6632691712.0000 - val_coeff_determination: 0.3561\n",
      "Epoch 273/500\n",
      "123/125 [============================>.] - ETA: 1s - loss: 5753980928.0000 - coeff_determination: 0.5068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 69s 553ms/step - loss: 5758772224.0000 - coeff_determination: 0.5060 - val_loss: 6526941184.0000 - val_coeff_determination: 0.3685\n",
      "Epoch 367/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5741861376.0000 - coeff_determination: 0.4994 - val_loss: 6522080256.0000 - val_coeff_determination: 0.3697\n",
      "Epoch 368/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5742405632.0000 - coeff_determination: 0.5034 - val_loss: 6395468288.0000 - val_coeff_determination: 0.3885\n",
      "Epoch 369/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5744579072.0000 - coeff_determination: 0.5019 - val_loss: 6456019968.0000 - val_coeff_determination: 0.3780\n",
      "Epoch 370/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5789431296.0000 - coeff_determination: 0.4987 - val_loss: 6540060672.0000 - val_coeff_determination: 0.3678\n",
      "Epoch 371/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5756768256.0000 - coeff_determination: 0.5042 - val_loss: 6451245056.0000 - val_coeff_determination: 0.3780\n",
      "Epoch 372/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5759439872.0000 - coeff_determination: 0.5044 - val_loss: 6465773568.0000 - val_coeff_determination: 0.3769\n",
      "Epoch 373/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5771333632.0000 - coeff_determination: 0.4998 - val_loss: 6411397632.0000 - val_coeff_determination: 0.3839\n",
      "Epoch 374/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5769537536.0000 - coeff_determination: 0.5013 - val_loss: 6611575296.0000 - val_coeff_determination: 0.3685\n",
      "Epoch 375/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5764122112.0000 - coeff_determination: 0.5025 - val_loss: 6442153984.0000 - val_coeff_determination: 0.3805\n",
      "Epoch 376/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5753271296.0000 - coeff_determination: 0.5050 - val_loss: 6499658752.0000 - val_coeff_determination: 0.3727\n",
      "Epoch 377/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5749911040.0000 - coeff_determination: 0.5049 - val_loss: 6476701184.0000 - val_coeff_determination: 0.3756\n",
      "Epoch 378/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5741185024.0000 - coeff_determination: 0.5063 - val_loss: 6619787264.0000 - val_coeff_determination: 0.3587\n",
      "Epoch 379/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5752670720.0000 - coeff_determination: 0.5037 - val_loss: 6445507584.0000 - val_coeff_determination: 0.3788\n",
      "Epoch 380/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5763127296.0000 - coeff_determination: 0.5018 - val_loss: 6477929472.0000 - val_coeff_determination: 0.3750\n",
      "Epoch 381/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5762182656.0000 - coeff_determination: 0.5022 - val_loss: 6545217536.0000 - val_coeff_determination: 0.3672\n",
      "Epoch 382/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5754682368.0000 - coeff_determination: 0.5025 - val_loss: 6697332224.0000 - val_coeff_determination: 0.3505\n",
      "Epoch 383/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5752455680.0000 - coeff_determination: 0.5026 - val_loss: 6604473344.0000 - val_coeff_determination: 0.3615\n",
      "Epoch 384/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5759407104.0000 - coeff_determination: 0.5008 - val_loss: 6573926400.0000 - val_coeff_determination: 0.3661\n",
      "Epoch 385/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5752463872.0000 - coeff_determination: 0.4977 - val_loss: 6564249088.0000 - val_coeff_determination: 0.3666\n",
      "Epoch 386/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5749612544.0000 - coeff_determination: 0.5020 - val_loss: 6496593920.0000 - val_coeff_determination: 0.3729\n",
      "Epoch 387/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5773732864.0000 - coeff_determination: 0.5027 - val_loss: 6611610112.0000 - val_coeff_determination: 0.3605\n",
      "Epoch 388/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5749027840.0000 - coeff_determination: 0.5029 - val_loss: 6533060096.0000 - val_coeff_determination: 0.3678\n",
      "Epoch 389/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5757919232.0000 - coeff_determination: 0.5047 - val_loss: 6440613888.0000 - val_coeff_determination: 0.3825\n",
      "Epoch 390/500\n",
      "  3/125 [..............................] - ETA: 1:06 - loss: 5572350976.0000 - coeff_determination: 0.5096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 69s 554ms/step - loss: 5759425024.0000 - coeff_determination: 0.5025 - val_loss: 6416269824.0000 - val_coeff_determination: 0.3836\n",
      "Epoch 486/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5739545088.0000 - coeff_determination: 0.5029 - val_loss: 6590536704.0000 - val_coeff_determination: 0.3631\n",
      "Epoch 487/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5750680576.0000 - coeff_determination: 0.5015 - val_loss: 6592461312.0000 - val_coeff_determination: 0.3638\n",
      "Epoch 488/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5748602368.0000 - coeff_determination: 0.5030 - val_loss: 6496378368.0000 - val_coeff_determination: 0.3731\n",
      "Epoch 489/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5737216000.0000 - coeff_determination: 0.5060 - val_loss: 6652797952.0000 - val_coeff_determination: 0.3550\n",
      "Epoch 490/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5738462208.0000 - coeff_determination: 0.5041 - val_loss: 6539719168.0000 - val_coeff_determination: 0.3673\n",
      "Epoch 491/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5724293120.0000 - coeff_determination: 0.5061 - val_loss: 6603389952.0000 - val_coeff_determination: 0.3603\n",
      "Epoch 492/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5742140416.0000 - coeff_determination: 0.5010 - val_loss: 6453246464.0000 - val_coeff_determination: 0.3794\n",
      "Epoch 493/500\n",
      "125/125 [==============================] - 69s 553ms/step - loss: 5750152704.0000 - coeff_determination: 0.5075 - val_loss: 6619427840.0000 - val_coeff_determination: 0.3583\n",
      "Epoch 494/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5738290688.0000 - coeff_determination: 0.5055 - val_loss: 6491106304.0000 - val_coeff_determination: 0.3736\n",
      "Epoch 495/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5736813568.0000 - coeff_determination: 0.5021 - val_loss: 6500921856.0000 - val_coeff_determination: 0.3722\n",
      "Epoch 496/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5732543488.0000 - coeff_determination: 0.5020 - val_loss: 6474427904.0000 - val_coeff_determination: 0.3756\n",
      "Epoch 497/500\n",
      "125/125 [==============================] - 69s 554ms/step - loss: 5749711360.0000 - coeff_determination: 0.5031 - val_loss: 6542427648.0000 - val_coeff_determination: 0.3676\n",
      "Epoch 498/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5740230144.0000 - coeff_determination: 0.5034 - val_loss: 6596697600.0000 - val_coeff_determination: 0.3608\n",
      "Epoch 499/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5754803200.0000 - coeff_determination: 0.5024 - val_loss: 6402497536.0000 - val_coeff_determination: 0.3848\n",
      "Epoch 500/500\n",
      "125/125 [==============================] - 69s 555ms/step - loss: 5756022272.0000 - coeff_determination: 0.5006 - val_loss: 6399975424.0000 - val_coeff_determination: 0.3865\n"
     ]
    }
   ],
   "source": [
    "\"\"\"cnn_history = cnn_satellite.fit(X_train1_cnn, \n",
    "                  y_train1_cnn, \n",
    "                  batch_size=batchsize, \n",
    "                  epochs=epochs, \n",
    "                  verbose=1, \n",
    "                  validation_data=(X_val_cnn, y_val_cnn))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 14ms/step - loss: 6399974400.0000 - coeff_determination: 0.3256\n"
     ]
    }
   ],
   "source": [
    "test_eval = cnn_satellite.evaluate(X_val_cnn, y_val_cnn, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(epochs)], cnn_history.history['val_coeff_determination'], \n",
    "         color = 'grey',\n",
    "        lw = .5)\n",
    "plt.scatter([i for i in range(epochs)], \n",
    "            cnn_history.history['val_coeff_determination'],\n",
    "            s=4)\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation $R^2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_malawi_500epochs/assets\n"
     ]
    }
   ],
   "source": [
    "#cnn_satellite.save('cnn_malawi_500epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50\n",
    "\n",
    "Cite\n",
    "https://arxiv.org/abs/1603.05027\n",
    "\n",
    "@misc{https://doi.org/10.48550/arxiv.1603.05027,\n",
    "  doi = {10.48550/ARXIV.1603.05027},\n",
    "  \n",
    "  url = {https://arxiv.org/abs/1603.05027},\n",
    "  \n",
    "  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},\n",
    "  \n",
    "  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},\n",
    "  \n",
    "  title = {Identity Mappings in Deep Residual Networks},\n",
    "  \n",
    "  publisher = {arXiv},\n",
    "  \n",
    "  year = {2016},\n",
    "  \n",
    "  copyright = {arXiv.org perpetual, non-exclusive license}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.ResNet50V2(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, None, None,   0           ['input_12[0][0]']               \n",
      "                                3)                                                                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, None, None,   9472        ['conv1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, None, None,   0           ['conv1_conv[0][0]']             \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, None, None,   0           ['pool1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, None, None,   256        ['pool1_pool[0][0]']             \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, None, None,   0          ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                        64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, None, None,   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                64)                              ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, None, None,   0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, None, None,   0          ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                           64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, None, None,   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, None, None,   0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, None, None,   16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, None, None,   0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                256)                              'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, None, None,   1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, None, None,   0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                        256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, None, None,   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                64)                              ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, None, None,   0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, None, None,   0          ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                           64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, None, None,   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, None, None,   0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                256)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, None, None,   0           ['conv2_block1_out[0][0]',       \n",
      "                                256)                              'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, None, None,   1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, None, None,   0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                        256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, None, None,   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                64)                              ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, None, None,   0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, None, None,   0          ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                           64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, None, None,   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, None, None,   0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_15 (MaxPooling2D  (None, None, None,   0          ['conv2_block2_out[0][0]']       \n",
      " )                              256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, None, None,   0           ['max_pooling2d_15[0][0]',       \n",
      "                                256)                              'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, None, None,   1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, None, None,   0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                        256)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, None, None,   32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                128)                             ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, None, None,   0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, None, None,   0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                           128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, None, None,   147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, None, None,   0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, None, None,   131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                512)                             ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, None, None,   0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                512)                              'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, None, None,   2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, None, None,   0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                        512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, None, None,   65536       ['conv3_block2_preact_relu[0][0]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                128)                             ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, None, None,   0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, None, None,   0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                           128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, None, None,   147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, None, None,   0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, None, None,   0           ['conv3_block1_out[0][0]',       \n",
      "                                512)                              'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, None, None,   2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, None, None,   0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                        512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, None, None,   65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                128)                             ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, None, None,   0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, None, None,   0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                           128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, None, None,   147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, None, None,   0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, None, None,   0           ['conv3_block2_out[0][0]',       \n",
      "                                512)                              'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, None, None,   2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, None, None,   0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                        512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, None, None,   65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                128)                             ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, None, None,   0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, None, None,   0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                           128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, None, None,   147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block4_2_relu (Activatio  (None, None, None,   0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_16 (MaxPooling2D  (None, None, None,   0          ['conv3_block3_out[0][0]']       \n",
      " )                              512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, None, None,   0           ['max_pooling2d_16[0][0]',       \n",
      "                                512)                              'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, None, None,   2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, None, None,   0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                        512)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, None, None,   131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, None, None,   0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, None, None,   0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                           256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, None, None,   589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, None, None,   0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, None, None,   525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                1024)                            ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, None, None,   0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                1024)                             'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, None, None,   4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, None, None,   0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, None, None,   262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, None, None,   0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, None, None,   0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                           256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, None, None,   589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, None, None,   0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, None, None,   0           ['conv4_block1_out[0][0]',       \n",
      "                                1024)                             'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, None, None,   4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  1024)                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, None, None,   0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, None, None,   262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, None, None,   0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, None, None,   0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                           256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, None, None,   589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, None, None,   0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, None, None,   0           ['conv4_block2_out[0][0]',       \n",
      "                                1024)                             'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, None, None,   4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, None, None,   0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, None, None,   262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, None, None,   0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, None, None,   0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                           256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, None, None,   589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, None, None,   0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, None, None,   0           ['conv4_block3_out[0][0]',       \n",
      "                                1024)                             'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, None, None,   4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, None, None,   0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, None, None,   262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, None, None,   0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, None, None,   0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                           256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, None, None,   589824      ['conv4_block5_2_pad[0][0]']     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, None, None,   0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, None, None,   0           ['conv4_block4_out[0][0]',       \n",
      "                                1024)                             'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, None, None,   4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, None, None,   0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, None, None,   262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, None, None,   0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, None, None,   0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                           256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, None, None,   589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, None, None,   0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_17 (MaxPooling2D  (None, None, None,   0          ['conv4_block5_out[0][0]']       \n",
      " )                              1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, None, None,   0           ['max_pooling2d_17[0][0]',       \n",
      "                                1024)                             'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, None, None,   4096       ['conv4_block6_out[0][0]']       \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, None, None,   0          ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                        1024)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, None, None,   524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                512)                             ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, None, None,   0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, None, None,   0          ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                           512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, None, None,   2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, None, None,   0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, None, None,   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                2048)                            ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv5_block1_out (Add)         (None, None, None,   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                2048)                             'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, None, None,   8192       ['conv5_block1_out[0][0]']       \n",
      " ormalization)                  2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, None, None,   0          ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                        2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, None, None,   1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                512)                             ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, None, None,   0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, None, None,   0          ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                           512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, None, None,   2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, None, None,   0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, None, None,   0           ['conv5_block1_out[0][0]',       \n",
      "                                2048)                             'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, None, None,   8192       ['conv5_block2_out[0][0]']       \n",
      " ormalization)                  2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, None, None,   0          ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                        2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, None, None,   1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                512)                             ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, None, None,   0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, None, None,   0          ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                           512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, None, None,   2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, None, None,   0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, None, None,   0           ['conv5_block2_out[0][0]',       \n",
      "                                2048)                             'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, None, None,   8192        ['conv5_block3_out[0][0]']       \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, None, None,   0           ['post_bn[0][0]']                \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,564,800\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,564,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = resnet(inputs, training=False)\n",
    "\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "#x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(32, activation='linear')(x)\n",
    "#x = keras.layers.Dropout(.2)(x)\n",
    "#x = keras.layers.LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1, activation = 'linear')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cnn_res50 = applications.resnet_v2.preprocess_input(\n",
    "    X_train1_cnn)\n",
    "\n",
    "#X_cnn_res50_val = applications.resnet_v2.preprocess_input(\n",
    "#    X_train1_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.mean_squared_error, \n",
    "            optimizer=keras.optimizers.Adam(),\n",
    "            metrics=[coeff_determination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "167/167 [==============================] - 10s 48ms/step - loss: 12132400128.0000 - coeff_determination: -0.0376\n",
      "Epoch 2/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 12119429120.0000 - coeff_determination: -0.0351\n",
      "Epoch 3/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 12097121280.0000 - coeff_determination: -0.0314\n",
      "Epoch 4/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 12066774016.0000 - coeff_determination: -0.0320\n",
      "Epoch 5/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 12032739328.0000 - coeff_determination: -0.0261\n",
      "Epoch 6/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11997116416.0000 - coeff_determination: -0.0244\n",
      "Epoch 7/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11963144192.0000 - coeff_determination: -0.0206\n",
      "Epoch 8/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11932553216.0000 - coeff_determination: -0.0186\n",
      "Epoch 9/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11906549760.0000 - coeff_determination: -0.0165\n",
      "Epoch 10/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11885782016.0000 - coeff_determination: -0.0183\n",
      "Epoch 11/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11870637056.0000 - coeff_determination: -0.0138\n",
      "Epoch 12/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11859567616.0000 - coeff_determination: -0.0143\n",
      "Epoch 13/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11851506688.0000 - coeff_determination: -0.0152\n",
      "Epoch 14/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11846072320.0000 - coeff_determination: -0.0147\n",
      "Epoch 15/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11842400256.0000 - coeff_determination: -0.0151\n",
      "Epoch 16/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11840037888.0000 - coeff_determination: -0.0137\n",
      "Epoch 17/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11838546944.0000 - coeff_determination: -0.0147\n",
      "Epoch 18/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11837590528.0000 - coeff_determination: -0.0151\n",
      "Epoch 19/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11836878848.0000 - coeff_determination: -0.0139\n",
      "Epoch 20/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11836619776.0000 - coeff_determination: -0.0142\n",
      "Epoch 21/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11836232704.0000 - coeff_determination: -0.0135\n",
      "Epoch 22/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11836043264.0000 - coeff_determination: -0.0129\n",
      "Epoch 23/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835906048.0000 - coeff_determination: -0.0131\n",
      "Epoch 24/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835799552.0000 - coeff_determination: -0.0152\n",
      "Epoch 25/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835885568.0000 - coeff_determination: -0.0154\n",
      "Epoch 26/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835786240.0000 - coeff_determination: -0.0141\n",
      "Epoch 27/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835786240.0000 - coeff_determination: -0.0139\n",
      "Epoch 28/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835816960.0000 - coeff_determination: -0.0160\n",
      "Epoch 29/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835792384.0000 - coeff_determination: -0.0137\n",
      "Epoch 30/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835823104.0000 - coeff_determination: -0.0151\n",
      "Epoch 31/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835732992.0000 - coeff_determination: -0.0120\n",
      "Epoch 32/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835692032.0000 - coeff_determination: -0.0117\n",
      "Epoch 33/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835696128.0000 - coeff_determination: -0.0155\n",
      "Epoch 34/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835797504.0000 - coeff_determination: -0.0137\n",
      "Epoch 35/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835728896.0000 - coeff_determination: -0.0102\n",
      "Epoch 36/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835872256.0000 - coeff_determination: -0.0160\n",
      "Epoch 37/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835752448.0000 - coeff_determination: -0.0155\n",
      "Epoch 38/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835715584.0000 - coeff_determination: -0.0143\n",
      "Epoch 39/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835805696.0000 - coeff_determination: -0.0137\n",
      "Epoch 40/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835906048.0000 - coeff_determination: -0.0144\n",
      "Epoch 41/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835815936.0000 - coeff_determination: -0.0129\n",
      "Epoch 42/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835798528.0000 - coeff_determination: -0.0152\n",
      "Epoch 43/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835732992.0000 - coeff_determination: -0.0161\n",
      "Epoch 44/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835803648.0000 - coeff_determination: -0.0140\n",
      "Epoch 45/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835716608.0000 - coeff_determination: -0.0157\n",
      "Epoch 46/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835763712.0000 - coeff_determination: -0.0150\n",
      "Epoch 47/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835749376.0000 - coeff_determination: -0.0140\n",
      "Epoch 48/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835782144.0000 - coeff_determination: -0.0153\n",
      "Epoch 49/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835660288.0000 - coeff_determination: -0.0147\n",
      "Epoch 50/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835820032.0000 - coeff_determination: -0.0148\n",
      "Epoch 51/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835686912.0000 - coeff_determination: -0.0160\n",
      "Epoch 52/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835703296.0000 - coeff_determination: -0.0151\n",
      "Epoch 53/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835728896.0000 - coeff_determination: -0.0137\n",
      "Epoch 54/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835786240.0000 - coeff_determination: -0.0159\n",
      "Epoch 55/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835737088.0000 - coeff_determination: -0.0163\n",
      "Epoch 56/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835746304.0000 - coeff_determination: -0.0135\n",
      "Epoch 57/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835756544.0000 - coeff_determination: -0.0150\n",
      "Epoch 58/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835850752.0000 - coeff_determination: -0.0176\n",
      "Epoch 59/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835717632.0000 - coeff_determination: -0.0137\n",
      "Epoch 60/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835751424.0000 - coeff_determination: -0.0154\n",
      "Epoch 61/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835672576.0000 - coeff_determination: -0.0164\n",
      "Epoch 62/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835653120.0000 - coeff_determination: -0.0126\n",
      "Epoch 63/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835752448.0000 - coeff_determination: -0.0153\n",
      "Epoch 64/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835703296.0000 - coeff_determination: -0.0151\n",
      "Epoch 65/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835768832.0000 - coeff_determination: -0.0157\n",
      "Epoch 66/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835694080.0000 - coeff_determination: -0.0121\n",
      "Epoch 67/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835773952.0000 - coeff_determination: -0.0125\n",
      "Epoch 68/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835762688.0000 - coeff_determination: -0.0130\n",
      "Epoch 69/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835755520.0000 - coeff_determination: -0.0140\n",
      "Epoch 70/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835760640.0000 - coeff_determination: -0.0146\n",
      "Epoch 71/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835677696.0000 - coeff_determination: -0.0144\n",
      "Epoch 72/150\n",
      "167/167 [==============================] - 9s 52ms/step - loss: 11835806720.0000 - coeff_determination: -0.0159\n",
      "Epoch 73/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835752448.0000 - coeff_determination: -0.0129\n",
      "Epoch 74/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835699200.0000 - coeff_determination: -0.0152\n",
      "Epoch 75/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835667456.0000 - coeff_determination: -0.0130\n",
      "Epoch 76/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835734016.0000 - coeff_determination: -0.0133\n",
      "Epoch 77/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835711488.0000 - coeff_determination: -0.0128\n",
      "Epoch 78/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835732992.0000 - coeff_determination: -0.0140\n",
      "Epoch 79/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835773952.0000 - coeff_determination: -0.0131\n",
      "Epoch 80/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835703296.0000 - coeff_determination: -0.0134\n",
      "Epoch 81/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835767808.0000 - coeff_determination: -0.0135\n",
      "Epoch 82/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835852800.0000 - coeff_determination: -0.0149\n",
      "Epoch 83/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835750400.0000 - coeff_determination: -0.0159\n",
      "Epoch 84/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835670528.0000 - coeff_determination: -0.0115\n",
      "Epoch 85/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835672576.0000 - coeff_determination: -0.0134\n",
      "Epoch 86/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835725824.0000 - coeff_determination: -0.0139\n",
      "Epoch 87/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835745280.0000 - coeff_determination: -0.0129\n",
      "Epoch 88/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835723776.0000 - coeff_determination: -0.0159\n",
      "Epoch 89/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835747328.0000 - coeff_determination: -0.0157\n",
      "Epoch 90/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835684864.0000 - coeff_determination: -0.0125\n",
      "Epoch 91/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835678720.0000 - coeff_determination: -0.0126\n",
      "Epoch 92/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835805696.0000 - coeff_determination: -0.0152\n",
      "Epoch 93/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835732992.0000 - coeff_determination: -0.0159\n",
      "Epoch 94/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835715584.0000 - coeff_determination: -0.0130\n",
      "Epoch 95/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835764736.0000 - coeff_determination: -0.0139\n",
      "Epoch 96/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835747328.0000 - coeff_determination: -0.0134\n",
      "Epoch 97/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835734016.0000 - coeff_determination: -0.0127\n",
      "Epoch 98/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835720704.0000 - coeff_determination: -0.0145\n",
      "Epoch 99/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835762688.0000 - coeff_determination: -0.0122\n",
      "Epoch 100/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835909120.0000 - coeff_determination: -0.0159\n",
      "Epoch 101/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835742208.0000 - coeff_determination: -0.0166\n",
      "Epoch 102/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835858944.0000 - coeff_determination: -0.0148\n",
      "Epoch 103/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835704320.0000 - coeff_determination: -0.0122\n",
      "Epoch 104/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835707392.0000 - coeff_determination: -0.0128\n",
      "Epoch 105/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835772928.0000 - coeff_determination: -0.0133\n",
      "Epoch 106/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835763712.0000 - coeff_determination: -0.0124\n",
      "Epoch 107/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835720704.0000 - coeff_determination: -0.0131\n",
      "Epoch 108/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835729920.0000 - coeff_determination: -0.0120\n",
      "Epoch 109/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835710464.0000 - coeff_determination: -0.0144\n",
      "Epoch 110/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835707392.0000 - coeff_determination: -0.0148\n",
      "Epoch 111/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835694080.0000 - coeff_determination: -0.0139\n",
      "Epoch 112/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835742208.0000 - coeff_determination: -0.0098\n",
      "Epoch 113/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835723776.0000 - coeff_determination: -0.0159\n",
      "Epoch 114/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835685888.0000 - coeff_determination: -0.0136\n",
      "Epoch 115/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835926528.0000 - coeff_determination: -0.0168\n",
      "Epoch 116/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835738112.0000 - coeff_determination: -0.0154\n",
      "Epoch 117/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835794432.0000 - coeff_determination: -0.0145\n",
      "Epoch 118/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835719680.0000 - coeff_determination: -0.0136\n",
      "Epoch 119/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835703296.0000 - coeff_determination: -0.0160\n",
      "Epoch 120/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835773952.0000 - coeff_determination: -0.0148\n",
      "Epoch 121/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835727872.0000 - coeff_determination: -0.0148\n",
      "Epoch 122/150\n",
      "167/167 [==============================] - 10s 61ms/step - loss: 11835952128.0000 - coeff_determination: -0.0187\n",
      "Epoch 123/150\n",
      "167/167 [==============================] - 10s 59ms/step - loss: 11835773952.0000 - coeff_determination: -0.0172\n",
      "Epoch 124/150\n",
      "167/167 [==============================] - 9s 54ms/step - loss: 11835738112.0000 - coeff_determination: -0.0136\n",
      "Epoch 125/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835747328.0000 - coeff_determination: -0.0180\n",
      "Epoch 126/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835747328.0000 - coeff_determination: -0.0160\n",
      "Epoch 127/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835784192.0000 - coeff_determination: -0.0129\n",
      "Epoch 128/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835741184.0000 - coeff_determination: -0.0121\n",
      "Epoch 129/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835665408.0000 - coeff_determination: -0.0158\n",
      "Epoch 130/150\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 11835712512.0000 - coeff_determination: -0.0120\n",
      "Epoch 131/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 8s 50ms/step - loss: 11835689984.0000 - coeff_determination: -0.0133\n",
      "Epoch 132/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835680768.0000 - coeff_determination: -0.0130\n",
      "Epoch 133/150\n",
      "167/167 [==============================] - 8s 51ms/step - loss: 11835880448.0000 - coeff_determination: -0.0157\n",
      "Epoch 134/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835700224.0000 - coeff_determination: -0.0148\n",
      "Epoch 135/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835710464.0000 - coeff_determination: -0.0151\n",
      "Epoch 136/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835788288.0000 - coeff_determination: -0.0174\n",
      "Epoch 137/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835694080.0000 - coeff_determination: -0.0149\n",
      "Epoch 138/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835745280.0000 - coeff_determination: -0.0139\n",
      "Epoch 139/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835710464.0000 - coeff_determination: -0.0132\n",
      "Epoch 140/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835776000.0000 - coeff_determination: -0.0148\n",
      "Epoch 141/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835723776.0000 - coeff_determination: -0.0142\n",
      "Epoch 142/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835820032.0000 - coeff_determination: -0.0123\n",
      "Epoch 143/150\n",
      "167/167 [==============================] - 9s 52ms/step - loss: 11835759616.0000 - coeff_determination: -0.0137\n",
      "Epoch 144/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835716608.0000 - coeff_determination: -0.0133\n",
      "Epoch 145/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835715584.0000 - coeff_determination: -0.0122\n",
      "Epoch 146/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835872256.0000 - coeff_determination: -0.0163\n",
      "Epoch 147/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835719680.0000 - coeff_determination: -0.0127\n",
      "Epoch 148/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835717632.0000 - coeff_determination: -0.0138\n",
      "Epoch 149/150\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 11835686912.0000 - coeff_determination: -0.0144\n",
      "Epoch 150/150\n",
      "167/167 [==============================] - 12s 69ms/step - loss: 11835721728.0000 - coeff_determination: -0.0133\n"
     ]
    }
   ],
   "source": [
    "resnet_history = model.fit(X_cnn_preped, \n",
    "          y_train1_cnn, \n",
    "          epochs=150,\n",
    "          batch_size = 75 \n",
    "          #,callbacks=...\n",
    "          #,validation_data= (X_cnn_res50_val, y_val_cnn)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22772"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(150)], resnet_history.history['coeff_determination'], color = 'grey')\n",
    "plt.scatter([i for i in range(150)], resnet_history.history['coeff_determination'])\n",
    "plt.grid()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation $R^2$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmapping\n",
    "\n",
    "Load model and hope it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e9ef68bf9d1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmalawi_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn_malawi_500epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "malawi_model = keras.models.load_model('cnn_malawi_500epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resnet_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-26307b282258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresnet_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'resnet_history' is not defined"
     ]
    }
   ],
   "source": [
    "resnet_history.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "image_size = 224\n",
    "\n",
    "# Load pre-trained Keras model and the image to classify\n",
    "model = cnn_satellite\n",
    "image = np.random.random((image_size, image_size, 3))\n",
    "img_tensor = preprocessing.image.img_to_array(image)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor = preprocess_input(img_tensor)\n",
    "\n",
    "conv_layer = model.get_layer(\"block5_conv3\")\n",
    "heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])\n",
    "\n",
    "# Get gradient of the winner class w.r.t. the output of the (last) conv. layer\n",
    "with tf.GradientTape() as gtape:\n",
    "    conv_output, predictions = heatmap_model(img_tensor)\n",
    "    loss = predictions[:, np.argmax(predictions[0])]\n",
    "    grads = gtape.gradient(loss, conv_output)\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "max_heat = np.max(heatmap)\n",
    "if max_heat == 0:\n",
    "    max_heat = 1e-10\n",
    "heatmap /= max_heat\n",
    "\n",
    "print(heatmap.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0457aa813e0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_pca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_pca' is not defined"
     ]
    }
   ],
   "source": [
    "svr.fit(X_train_pca, y_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4dd5c14f1627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tf.keras.utils.plot_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcnn_satellite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model.png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mshow_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    cnn_satellite,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
